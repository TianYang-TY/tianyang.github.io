{"posts":[{"title":"我的密码折腾之路","content":"原来我的密码风格都是网站名加固定密码的组合方式，存在一点点的安全隐患。之前就在 TESTV 节目里看到过 1PassWord 的强大功能，可惜不是睾贵的苹果用户，目前 1PassWord 也有安卓和 Windows 端，只是体验不佳，而且每年还都有白嫖活动。在去年疫情时的心血来潮想要使用密码管理器，本着能不花钱就不花钱，能用开源的就用开源的原则，就走上了这条折腾的不归路。 KeePass 首先使用的是最为老牌的 KeePass 了，一开始是迟到了知乎一篇文章的安利（一劳永逸：KeePass全网最详使用指南 - 知乎 (zhihu.com) ），正好自己是坚果云的高强度用户，密码备份有着落，就跟着教程一步一步的配置了 KeePass 的环境，并且一直使用了一年左右。 KeePass 作为老牌开源软件，其功能性是毋庸置疑的。自动混淆输入，丰富的插件支持，多种备份方式支持等等，都是非常强大而且实用的功能。同时由于其开源特性，在各平台有着各种各样的客户端，Windows 上有官方的 KeePass2，还有经典的 KeePassXC 等等，也是由于其开源社区维护的特性，这些软件的 UI 充满了复古气息，操作上也比较复杂，使用起来多有不便。 经过很长时间的磨合，在 Windows 端我依然选择的是最丑同时也是功能最全的 KeePass2，最大的需求是 Windows Hello 的支持，当然这个支持需要插件来完成，另外对于两步验证也就是 TOTP 的支持也是可以使用插件来完成的；在安卓端，一开始使用的是 KeePass2Android，这也是大多数人的选择，安卓平台也有 KeePassXc 可以选择，只是作者不愿意支持联网同步，无法满足我的需求，后来在酷安发现了一个新秀 KeePassA，也是开源的，对于指纹、TOTP的支持也是完整的，更重要的是 UI 非常的舒服，所以后来就转向了 KeePassA。 Bitwarden 其实因为 KeePass 太丑，一直想要找一个合适的替代品，在 V2EX 的密码管理器日经贴中，很多人一直在提 Bitwarden，便萌生了使用的念头，一开始使用了官方版，发现免费版本不能使用 TOTP，对自己搭建密码管理器心存芥蒂，总怕哪天服务器崩了就把所有密码一锅端了。4 月初在知乎上发现了一篇使用腾讯云托管的方法搭建 Bitwarden 的方法，便试了一下。 腾讯云托管 用了4年密码管理神器KeePass，结果一试Bitwarden就回不去了！？ - 知乎 (zhihu.com)，这是那篇链接，详细记录了搭建的流程。腾讯云开发首次使用送一个月的免费资源，我就开始了入坑之旅。从使用的环境上看，不是原版的 Bitwarden Docker，而实备受好评的 bitwarden-rs，占用更低，使用腾讯云的流程搭建的服务会直接获得一个 HTTPS 的链接，不需要其他操作就可以直接使用了，注册之后需要添加一个禁用注册的环境变量。就这么使用了一个月，之间大概算了一下价格，正常一个人使用情况下，一个月五六块的样子，其实一开始都准备接受这个价格一直用下去了，就在前两天突然就崩了，重新部署一直失败，就放弃了。总结一下腾讯云的最大优点就是一键部署，非常省事，可惜就是稳定性太差，他的 GitHub 仓库里也是有很多人反馈说不稳定，还有一个非常影响体验的点，腾讯云的服务器在不使用的时候会休眠，唤醒需要等待一段时间。 在使用的这一个月里，感受到 Bitwarden 使用起来确实非常方便，使用最多的是浏览器插件，对网页的识别要优于 KeePass，填充起来也更舒适，所以腾讯云崩了之后便想着自建了。 自建 bitwarden-rs 因为腾讯云崩了，一开始是想着趁腾讯云服务器的活动还没结束，花个 89 买一年的服务器自己搭建，后来想到自己在 Oracle 上白嫖的终身免费服务器理论上能保持更长的时间，所以准备直接用 Oracle 的服务器试试。之前因为端口的问题，只在服务器上跑了一些小应用，完全没用过网页服务，后来找到了解决方案，这样操作之后还是不能 ping，但是端口已经开放了，可以正常搭建网页服务，就是这么离谱。为了测试端口能否正常搭建，我一开始使用了宝塔面板，后来想想也没啥用，有机会就直接卸载了。 # 首先需要设置安全组 将默认的安全组中的 ICMP 参数改成 8，TCP 协议开放目标端口 # 关闭 Ubuntu 系统内的防火墙 sudo iptables -P INPUT ACCEPT sudo iptables -P FORWARD ACCEPT sudo iptables -P OUTPUT ACCEPT sudo iptables -F 下面记录了自建 bitwarden-rs 时的所有操作： Docker 为了方便，使用的是 Docker compose，将容器的 data 文件夹映射到本地的 bw-data # docker-compose.yml version: '3' services: bitwarden: image: bitwardenrs/server:latest container_name: bitwarden restart: always volumes: - ./bw-data:/data env_file: - config.env ports: - &quot;2333:80&quot; #将2333端口映射到镜像80端口 environment: #WEBSOCKET_ENABLED: &quot;true&quot; #开启WebSocket SIGNUPS_ALLOWED: &quot;false&quot; #开启注册，自己注册后改成fale #WEB_VAULT_ENABLED: &quot;true&quot; #web客户端 Nginx 反代 因为不太会写 Nginx 的配置文件，现在使用的宝塔面板里的 Nginx 反代功能：首先去设置一个子域名解析到服务器 IP，然后在宝塔面板里新建一个空白的网站，直接设置反代即可，因为我用的是 CLoudFlare 的域名托管，所以就没申请 TTL 证书也能使用 HTTPS，如果需要申请证书，宝塔面板生成的空白网站就不太方便了。 宝塔面板有一天是要被卸载的，到时候再更新使用 Docker 部署 Nginx 的内容。 备份 使用自己搭建的服务，定时备份数据库是非常必要的，这里就使用网上找到的一个简单脚本，每周一定时备份到坚果云里。新建一个脚本如下内容，需要自行设定路径与文件夹，去坚果云里新建一个应用密码，在坚果云根目录新建一个 bitwarden 文件夹，使用 crontab 每周一零点定时执行这个脚本 0 0 * * 1 /bin/sh 脚本，并没有设置自动删除过期备份文件的功能，因为坚果云的文件不传输是不消耗流量的，而且一周备份一次的频率也不高，并不会积攒太多的文件，以后文件太多的话手动删除一部分就是了。 #!/bin/sh set -e filename=&quot;bitwarden-`date +%F`.tar.gz&quot; cd /root tar czf &quot;${filename}&quot; bw-data/ curl -u &quot;USERNAME:APP_PASSWD&quot; -T &quot;${filename}&quot; &quot;https://dav.jianguoyun.com/dav/bitwarden/&quot; rm &quot;${filename}&quot; 使用 电脑上使用的是 Bitwarden 的浏览器插件，桌面端几乎没有打开过，所以依赖桌面端的 Windows Hello 解锁就不能用了，现在设定的是每次锁定电脑时自动锁定数据库，也算是在安全性和便利性之间的一个折中。 手机端使用的是没有官方提供的不依赖谷歌框架的客户端，因为我嫌谷歌框架太耗电就禁用了。依赖于安卓本身支持密码管理器的特性，使用起来没有问题。 总结 经历一番波折，终于将密码管理从 KeePass 转换到 Bitwarden，其中走了不少偷懒的路，比如宝塔面板的 Nginx 反代，比如 CloudFlare 的 HTTPS，以后有机会继续完善。 使用密码管理器一开始确实是麻烦了一些，需要将自己原来的密码一个一个输入进去，简单的密码还需要去原网站修改密码，在这一切都设置好之后，使用起来便得心应手了，无论是安全性还是输密码的便捷性都比自己用脑子记一个密码要好。 ","link":"https://yangt.me/post/my-password-managers/"},{"title":"部分容积校正方法与操作","content":"部分容积校正（Partial Volume Correction）的目的是校正由于目标物体相对于分辨率大小的有限所造成的信号的损失，以及目标区域外的信号污染，即校正部分容积效应（Partial Volume Effect）。对于 PVE 与 PVC 的概念知识可以参考以下两篇知乎文章：Partial Volume Effect（部分容积效应） - 知乎 (zhihu.com), Partial Volume Correction（部分容积校正） - 知乎 (zhihu.com)。 下面记录了我使用 FreeSurfer 与 PETPVC 的 PVC 功能进行部分容积校正的内容。 FreeSurfer FreeSurfer 的安装与使用内容在另外两篇文档中已经记录，PVC 的内容主要包含在 PETSurfer 的内容中，之前根据官方文档的操作比较简单，下面是一些更为复杂的操作，操作时需要确保 Subject 已经经过了 recon-all 的操作。 FreeSurfer 的 PVC 使用的是 GTM 和 MG 方法，都是基于 VOI 的方法，所以需要确定一个标签图。在 FreeSurfer 中，可以使用 gtmseg 来创建一个自定义的标签图，或者使用默认的分割方式获得一个分割结果，下面就是终端运行 gtmseg --help 得到的一个结果。得到一个目标标签图之后就可以继续使用 mri_coreg 和 mri_gtmpvc 的命令去进行 PVC 的操作，操作参数与结果都在之前的文档中有写。 # gtmseg --help You can use your own segmentation or a modified FS segmentation. It will be easiest if you modify apas+head.mgz to insert your segmentations. apas+head.mgz is created by gtmseg but you can create it with xcerebralseg --s $subject --o $SUBJECTS_DIR/$subject/mri/apas+head.mgz To create a new segmentation by replacing voxels in apas+head.mgz with your segmentation: make sure that the index you give your new segmentation(s) is not already present in apas+head.mgz. Next create a color table text file that looks something like this: # TissueTypeSchema #ctTType 0 unknown 0 0 0 0 #ctTType 1 cortex 205 62 78 0 #ctTType 2 subcort_gm 230 148 34 0 #ctTType 3 wm 0 255 0 0 #ctTType 4 csf 120 18 134 0 #ctTType 5 head 150 150 200 0 265 MySeg 219 100 176 0 2 In the above case, it is assumed that the index that you used was 265 and that your segmentation is for subcortical gray matter (thus making the last number=2 in the MySeg row). If you have more than one segmentation you are adding, then add rows into the color table. The first 5 entries codes for the different possible tissue types. You can then run gtmseg --s subject --head apas+head+myseg.mgz \\ --ctab myseg.colortable.txt --o gtmseg+myseg.mgz where apas+head+myseg.mgz is apas+head.mgz with your new segmentation, myseg.colortable.txt is the color table you created, and gtmseg+myseg.mgz will be your output volume. Note that an output color table gtmseg+myseg.ctab will be generated. You should check in this to make sure that your segmentation appears. You can also run tkmeditfv subject orig.mgz -seg gtmseg+myseg.mgz myseg.colortable.txt PETPVC PETPVC 是一个开源的工具箱，集成了众多的 PVC 方法，当前最新版本为 1.2.4, 以下为安装与使用方法。 # 下载 wget https://github.com/UCL/PETPVC/releases/download/v1.2.4/PETPVC-1.2.4-Linux.tar.gz # 解压 tar -xzvf PETPVC-1.2.4-Linux.tar.gz # 设置环境变量 # 文件夹其实不必要放在 /usr/local/ 下，但是需要保证 .bashrc 文件中指向正确的路径 sudo cp -r PETPVC-1.2.4 /usr/local/PETPVC gedit ~/.bashrc # 拉到最后一行 PATH=$PATH:/usr/local/PETPVC/bin source ~/.bashrc 所有基于 VOI 的 PVC 方法在使用时均需要一个标签图，假设使用 FreeSurfer 获得的 gtmseg.mgz 文件作为标签图，下面为处理流程。 预处理 如果使用基于 VOI 的方法，需要确保 PET 图像与标签图具有同一物理空间和图像尺寸，否则无法进行 PVC，然后对标签图进行处理。如果使用纯基于体素的方法，不需要下面的预处理。 # 转为 nii/nii.gz - PETPVC 使用的 ITK, 转换为 ITK 能够识别的格式即可 mri_convert gtmseg.mgz gtmseg.nii.gz # 转换为 4D Mask，4D 文件中每个图像代表一个脑区 pvc_make4d -i gtmseg.nii.gz -o 4D_gtmseg.nii.gz PVC # 官方示例 petpvc -i &lt;PET&gt; -m &lt;MASK&gt; -o &lt;OUTPUT&gt; --pvc IY -x 6.0 -y 6.0 -z 6.0 [--debug] 其中 xyz 为 PET 图像采集时机器决定的参数 FWHM，如果使用的是完全基于体素的算法，比如 RL，那么不需要输入 m 参数。 如果观察之前解压出来的 PETPVC 安装文件夹，可以发现 /bin 目录下还存在不少以 PVC 方法命名的可执行文件，比如 pvc_gtm pvc_iy pvc_mg pvc_mtc pvc_rbv pvc_relabel pvc_rl pvc_vc 等，也可以直接调用特定的方法来执行，而且如果直接执行这些文件的话，可以看到专属的帮助文档，比如 pvc_rl 的文档，可以看到使用 petpvc 看不到的迭代次数等参数。 # pvc_rl Option petfile is required but not defined Option outputfile is required but not defined Option FWHMx is required but not defined Option FWHMy is required but not defined Option FWHMz is required but not defined Command tags: -x &lt; X &gt; = The full-width at half maximum in mm along x-axis -y &lt; Y &gt; = The full-width at half maximum in mm along y-axis -z &lt; Z &gt; = The full-width at half maximum in mm along z-axis [ -i --iter [ Val ] ] = Number of iterations With: Val (Default = 10) [ -d --debug ] = Prints debug information Command fields: &lt; petfile &gt; = PET filename &lt; outputfile &gt; = output filename 并行处理 这一步是在处理大量 PET 数据时一个节省时间的做法，不影响 PVC 效果，GNU Parallel 的安装与使用见之前的 FreeSurfer 操作文档，PETPVC 在处理时会进行多核运算，所以没必要并行太多，以免服务器内存爆满导致 PVC 失败。 # subject_id.txt 存储了待处理的 Subjects ID parallel -a subject_id.txt --jobs 4 petpvc -i ./PET/{}.nii.gz -o pvc_RL/{}.nii.gz --pvc RL -x 8 -y 8 -z 8 ","link":"https://yangt.me/post/partial-volume-correction/"},{"title":"毒瘤软件自救指南","content":"今日腾讯又双叒叕被曝光偷偷读取用户浏览器历史的丑陋行径（V2EX），但是 TIM 和微信又不能弃用，所以搜寻了一些方法来压制这些毒瘤（包括但不限于腾讯全家，百度全家。） 火绒 火绒可以自定义安全规则来保护某些文件夹，防止被恶意程序读取，设置路径为：高级设置 - 高级防护 - 自定义防护 ，添加自定义路径用来保护一些重要的文件夹，比如： # Edge / Chrome 历史记录 *\\\\User*Data\\\\Default* # SSH key ?:\\\\Users\\\\*\\\\.ssh\\* # FQ 软件 ?:\\\\Users\\\\*\\\\.config\\* *\\\\v2rayN_Core\\\\config.json 设置后会立竿见影，登录 TIM 后会收到火绒的提示。Edge 等软件以及 Windows 系统的一些服务在首次启动时也会被火绒拦截，手动允许并设置不再询问即可。下面是火绒安全日志的截图： Sandboxie Sandboxie 是一个老牌的沙箱类软件，已经从商业软件转向开源，现在社区维护的版本为 Sandboxie Plus , 用 QT 重写了原有 Sandboxie，变得好看了一些。我根据日常使用习惯，将三个软件请进了 Sandboxie 中：TIM，微信，百度网盘。微信和百度网盘比较简单，直接安装即可使用，TIM / QQ 需要一个恶心人的 QQProtect.exe 先运行，需要一番操作。主要操作学习自 V2EX ，帖子内容如下： 为每个腾讯系软件创建自己的沙盒环境 全局设置-软件兼容性-勾选 Windows 10 Core UI （解决 2004 版微软拼音不能输入问题） 在各自的沙盒安装软件，安装完成后先不启动，终止所有进程 双击沙盒进入沙盒设置，选择 资源访问-添加文件夹-访问-closed 如：（ C:\\Users\\用户名\\AppData\\Local 、C:\\Users\\用户名.config 、C:\\Users\\用户名.ssh ） [QQ/TIM 特殊操作]沙盒设置-通用选项-自动启动 添加 QQprotect.exe 的路径 沙盒设置-停止行为-添加引导程序 TIM.exe|QQ.exe-添加驻留程序 QQProtect.exe 为软件创建快捷方式，打开软件，在沙盒内找到主进程，右键创建快捷方式 可选： 关闭边界黄线 说明： （不进行）操作 2 会导致不能输入中文，或者需要在微软拼音中选择启用兼容性旧版输入法 操作 4 将所有不希望 TIM 获取到的文件夹写入，记得访问调成 closed，不然默认允许访问 操作 5 仅 QQ 、TIM 需要，目的是启动沙盒时自动启动 QQProtect 操作 6 目的是引导程序 TIM 停止后，自动停止 QQProtect 运行，做到 QQProtect 只能在 TIM 运行时运行 其中第五点经过测试不可用，TIM还是无法启动。可以使用以下方法启动： # 新建一个 bat 文件 # /box: 后面是自己设置的沙盒名称 @echo off &quot;C:\\Program Files\\Sandboxie\\Start.exe&quot; /box:Tim &quot;C:\\Program Files (x86)\\Common Files\\Tencent\\QQProtect\\Bin\\QQProtect.exe&quot; &quot;C:\\Program Files\\Sandboxie\\Start.exe&quot; /box:Tim &quot;C:\\Program Files (x86)\\Tencent\\TIM\\Bin\\TIM.exe&quot; 然后就可以看到毒瘤们老老实实待在沙箱中了 固定到开始菜单 个人习惯将软件固定到开始屏幕，方便随时启动，还能保持干净的桌面。微信和百度网盘安装之后可以按照上面帖子的方案将快捷方式固定，使用 bat 文件启动的 TIM 需要先给 bat 文件生成一个快捷方式，修改成 TIM 的图标（C:\\Sandbox\\XXX\\Tim\\drive\\C\\Program Files (x86)\\Tencent\\TIM\\TIMUninst.ico），然后把快捷方式放在 C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs 下。 ","link":"https://yangt.me/post/fxxk-tencent/"},{"title":"基于 VSCode 的 Python 开发环境","content":"本文记录电脑中基于 VSCode 进行 Python 开发环境的流程。初上手 Python 时，Pycharm 是一个非常便利的 IDE，随着使用频率的增加，愈发被 Pycharm 超慢的启动速度困扰，于是转入 VSCode。VSCode 定位是一个文本编辑器，并不是跟 Pycharm 一样的 IDE，得益于丰富的插件支持，可以自定义出一套满足自己需求的开发环境。 Python 安装 安装 Python 有两种途径，一种是去 Python 官网下载单独的 Python 安装包，另一种是使用 Anaconda 包管理器。目前使用的是 Anaconda 方法，在安装的同时也会附带更多的常用库，免得自己再逐个安装，并外还能够很方便的生成不同的虚拟环境，以应对不同的开发需求。如果只需要虚拟环境，不需要那么多的库，可以使用 miniconda。 Anconda 的安装包可以从清华大学的镜像中下载，安装时需要注意设定到环境变量，否则 VSCode 中的终端无法执行 Python 程序。安装之后需要设定 conda 和 pip 的国内镜像源，提升下载速度，方法如下 清华 Anaconda 镜像帮助连接： https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/ 各系统都可以通过修改用户目录下的 .condarc 文件。Windows 用户无法直接创建名为 .condarc 的文件，可先执行 conda config --set show_channel_urls yes 生成该文件之后再修改。 channels: - defaults show_channel_urls: true channel_alias: https://mirrors.tuna.tsinghua.edu.cn/anaconda default_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud # 设置 pip 的源 pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple VSCode 安装 VSCode 是一个全平台通用的文本编辑器，在官网下载安装即可。 插件安装 Chinese (Simplified) Language Pack for Visual Studio Code / 中文语言包 将软件的语言设置为中文。 Python VSCode 的 Python 扩展，使 VSCode 拥有调用 Python 解释器的功能。安装成功之后可以新建一个 .py 文件，然后在窗口的左下角选择 Python 解释器，VSCode 会自动搜索系统中的 Python 环境。然后可以 print('hello world') 检查一下是否有问题。 Bracket Pair Colorizer 2 / 彩色括号 将不同的括号用不同的颜色标识，方便区分。 Dracula Official / 主题 VSCode 支持设置各种各样的主题，在扩展库搜索 Theme 即可出现所有可用主题。 Material Icon Theme / 图标主题 扁平化图标主题，颜值才是第一生产力。 Jupyter VSCode 现在已经支持了 Jupyter Notebook，装个插件就可以了。 Remote-SSH / 远程开发 可以让通过SSH连接远程服务器作为本地的开发环境，连接远程服务器最好使用 SSH key，不建议使用密码，否则会不停地在输入密码。 settings.json / 设置 VSCode 的 GUI 设置并不完善，更多还是直接操作 settings.json ， Ctrl+Shift+P 可以搜索 settings.json 打开，前面设置的主题、图标等都会在这里看到，另外还可以在这里设置字体等格式。 &quot;workbench.iconTheme&quot;: &quot;material-icon-theme&quot;, &quot;workbench.colorTheme&quot;: &quot;Dracula&quot;, &quot;editor.fontSize&quot;: 18, &quot;editor.lineHeight&quot;: 26, &quot;editor.fontFamily&quot;: &quot;Sarasa mono SC&quot;, &quot;terminal.integrated.fontSize&quot;: 16, &quot;terminal.integrated.lineHeight&quot;: 1.5, 自动补全与格式 Pylance Pylance 是微软新推出的 Python 语言服务器， 可以在插件库中安装，提供自动补全等功能。 yapf / 代码格式化 YAPF 是Google开源的一个用来格式化Python代码的工具，使用 pip install yapf 进行安装，首次在 VSCode 中按下快捷键 Shift+Alt+F 会弹窗选择格式化工具，之后可直接使用快捷键进行代码格式化，主要是注意代码缩进与 import 语句顺序等问题。 flake8 / 语法检查 语法检查工具有很多，包括 flake8，pylint 等，同样使用 pip install flake8 进行安装。默认的语法要求太过严格，可以在 settings.json 中进行设置 &quot;python.linting.flake8Enabled&quot;: true, &quot;python.linting.flake8Args&quot;: [ &quot;--max-line-length=120&quot;, &quot;--ignore=E401 E402,F841,F401,F403,E302,E305,W504&quot;, ] 未完待续... ","link":"https://yangt.me/post/vscode-python-dev/"},{"title":"上下对等千兆教育网冲浪指南","content":"坐标北方某大学，学校内教学楼WiFi全覆盖，寝室和实验室都有网口，实测速率可以达到上下对等的千兆速率，校内数据传输不计费，在有线网下会分配到一个固定的IP地址，这么棒的资源肯定要利用起来。教育网与普通运营商网很大的不同是学校内相当于一个大路由器，接入学校网络的设备可以自由访问校内IP地址，校外设备无法访问，我下面进行的操作也很大程度上基于此条件，也不需要购买服务器进行内网穿透。 远程操作 疫情期间Teamviewer的远程体验可谓是一言难尽，后来换了新电脑还不让我登录了，Anydesk、向日葵等替代品用起来也不爽，后来发现了Todesk这个神器，使用体验非常棒，就把Teamviewer卸载了，走好不见。 当然回到学校之后就不需要借助这些软件了，无论是远程电脑还是服务器都可以直接使用IP地址，实验室与寝室的ping值在1ms左右。远程Windows可以使用自带的RDP，用起来非常的流畅，有时候全屏之后会忘了自己在远程。实验室电脑在路由器下，可以在路由器后台设置静态IP和端口转发。Win10家庭版默认无法被远程，可以安装RDP Wrapper这个工具开启被远程功能。服务器一般是Ubuntu系统，远程有两种解决方案：SSH和VNC，分别对应终端和GUI，用起来都很流畅。 注意：由于RDP的特性，远程时使用的OpenGL版本太老，跟本地使用的版本不一致，会导致一些软件奔溃，日常的软件极少碰到这个问题。 下载 既然在教育网下自然要好好利用一下免费的IPV6资源了，之前还可以通过IPV6直连谷歌香港，现在不行了。目前最大的用处就是PT站了，教育网下有不少优质的PT站，可以用教育邮箱进行注册使用。实测热门资源也能够基本跑满我千兆的带宽。 除了PT站之外正常下载东西也是非常快的，前几天下载原神能维持在100M/s左右，11G流量分分钟就用完了。 数据传输 经常需要在实验室电脑和寝室笔记本之间传输数据（主要是看剧），直接在远程的时候复制粘贴不是那么方便，买个NAS也不太合适，所以我把笔记本的文件夹共享了出来，可以在校园网内访问。共享的方法有很多，Windows系统就自带了SMB和FTP两种分享方式，不过这两个功能做的太复杂还一股咖喱味，不太好用。找了一下发现Filezila的FTP功能非常方便，能很方便的设置权限和速度，就用Filezila在笔记本上搭了一个FTP服务器。实验室电脑端用的是Raidrive这个软件将FTP文件夹映射成带盘符的网络驱动器，映射之后这个文件夹就能跟本地文件一样进行预览打开等操作了，比系统自带的映射要好用很多。安卓端只有视频需求，所以用的是nplayer，如果有文件传输需求，还有一些软件可以做到。实测在Filezila不设置限速的情况下可以跑满带宽，100M/s已经快赶上机械硬盘的速度了。最重要的是，FTP可以共享我的PT下载文件夹，可以躺在床上看电脑上的视频了。 总结 教育网下的网络环境可能有些特殊，既然学校提供了这么好的网络资源，不用起来太可惜了，嘿嘿嘿。 ","link":"https://yangt.me/post/school-network/"},{"title":"Freesurfer操作文档","content":"本文档的操作流程基于 Ububtu 18.04LTS 以及 Freesurfer 6.0，安装过程记录在另一篇文档 在 Ubuntu18.04LTS 中安装 FreeSurfer 中。本文档操作全部在终端中进行，Freesurfer 的 GUI 仅用作查看操作结果。 创建于2020-03-07 修改1：2020-03-08 ​ 修正SUBJECTS_DIR的设置方法与单subject多图像的文件夹结构 ​ 修正recon-all在单subject多图像情况下的命令 修改2：2020-03-12 ​ 删除修改1中增加的单subject多图像情况 ​ 新增多图像的多线程处理内容 修改3：2020-04-15 ​ 新增DICOM转nii内容 修改4：2020-04-17 ​ 新增批处理提取统计学结果的内容 修改5：2020-04-27 ​ 新增PET处理内容 修改6：2020-05-12 ​ 加入PET后的批处理流程 修改7：2020-07-23 ​ 对PET分割限定线程数避免报错 补充了一些后续步骤 修改8：2020-11-02 新增海马子区域分割流程 SUBJECTS_DIR 首先需要用户自定义 SUBJECTS_DIR，不推荐使用放在 Freesurfer 安装目录下的默认文件夹，自定义 SUBJECTS_DIR 的命令如下：操作中严格避免中文路径的出现！！！ # 设置到桌面上 export SUBJECTS_DIR=/home/用户名/Desktop/Subjects # 快速设置为当前文件夹 export SUBJECTS_DIR=$(pwd) # 查看当前SUBJECTS_DIR echo $SUBJECTS_DIR 在 SUBJECTS_DIR 下，可以直接放置 sample-001.mgz, sample-002.mgz 等文件。下方文件夹结构为分割完成后的文件夹结构： SUBJECTS_DIR ├── sample-001 │ ├── label │ ├── mri │ │ ├── orig │ │ └── transforms │ │ └── bak │ ├── scripts │ ├── stats │ ├── surf │ ├── tmp │ ├── touch │ └── trash └── sample-002 ├──... recon-all recon-all 为 Freesurfer 的核心命令，使用命令 recon-all --help 可以查看详细帮助。在操作时可以使用以下命令切换到 SUBJECTS_DIR 下并执行 recon-all，如果需要同时处理多个图像，可以使用后面提到的 Parallel；如果需要处理文件夹形式的 DICOM 图像，可先用 dcm2niix 转换成 nii 格式。 cd $SUBJECTS_DIR # bert 是可自己设置的 subject 名字 recon-all -s bert -i sample-001.mgz -all 上面的命令成功执行后会持续数个小时，处理结果会分类存放在上一部分列出的文件夹结构中。 freeview 在终端中输入 freeview 进入 GUI，然后通过 File - Load Volume 加载 mri -&gt; T1.mgz / aseg.mgz / wm.mgz / brainmask.mgz，aseg.mgz是灰质白质等解构的分割结果，可以选择 Color map 为 Lookup Table 并调低透明度进行观察。 recon-all的结果中还包含了曲面信息，使用 File - Load Surface 加载 surf -&gt; lh.pial / lh.white / lh.inflated 以及对应的右脑文件 surf -&gt; rh.pial / rh.white / rh.inflated。 下面的命令行操作与上面的结果完全相同，无需重复操作： $&gt; freeview -v \\ bert/mri/T1.mgz \\ bert/mri/wm.mgz \\ bert/mri/brainmask.mgz \\ bert/mri/aseg.mgz:colormap=lut:opacity=0.2 \\ -f \\ bert/surf/lh.white:edgecolor=blue \\ bert/surf/lh.pial:edgecolor=red \\ bert/surf/rh.white:edgecolor=blue \\ bert/surf/rh.pial:edgecolor=red stats Freesurfer的 recon-all 命令已经处理的MR数据的体积以及皮层厚度信息，使用 asegstats2table, aparcstats2table 两个命令可以分别提取出。体积与皮层厚度结果均是按照已经分割好的脑区进行统计，皮层厚度只能对左脑和右脑分别输出。另外，这两个命令仅能输出txt格式文档，查看时需要使用excel进行转换。使用命令如下： # https://surfer.nmr.mgh.harvard.edu/fswiki/asegstats2table asegstats2table --subjects bert --common-segs --meas volume --stats=aseg.stats --table=segststs.txt # https://surfer.nmr.mgh.harvard.edu/fswiki/aparcstats2table # aparcstats2table 需要分别提取左右脑的结果 aparcstats2table --subjects bert --hemi lh --meas thickness --parc=aparc --tablefile=aparc.txt aparcstats2table --subjects bert --hemi rh --meas thickness --parc=aparc --tablefile=aparc.txt Parallel Freesurfer 本身无法同时对多个图像（多个 subjects ）进行计算，为了充分利用电脑的多核性能节省计算时间，需借助一个多线程工具，名为 GNU Parallel。Parallel 在 Ubuntu下可以直接使用 sudo apt-get install parallel 进行安装。多线程进行 recon-all 的命令如下，使用此方法会将每个图像的文件名作为分割该图像时的subject名字。执行此命令时可能没有信息在终端输出，执行完成后会一次性输出，如需查看进行状态，可以到 ./scripts/recon-all.log 查看 recon-all 日志. # mgz 为后缀，需要指定参与 CPU 参与计算的核心数则在 parallel 后加：--jobs 核心数 ls *.mgz | parallel recon-all –s {.} –i {} –all # 统计数据提取也可以使用 Parallel ls *.nii | parallel asegstats2table --subjects {.} --common-segs --meas volume --stats=aseg.stats --table=segststs_{.}.txt ls *.nii | parallel aparcstats2table --subjects {.} --hemi lh --meas thickness --parc=aparc --tablefile=aparc_{.}_lh.txt ls *.nii | parallel aparcstats2table --subjects {.} --hemi rh --meas thickness --parc=aparc --tablefile=aparc_{.}_rh.txt 对于上述 Parallel 导出的一系列统计txt文件，我编写了 python 程序转换成更易读的 csv 文件，将下面的文件保存为 txt2csv.py 然后放在当前的 SUBJECTS_DIR 下，在终端中执行 python txt2csv.py 即可进行转换。 import csv import os def txt2csv(inputfile, outputfile): datacsv = open(outputfile, 'w') csvwriter = csv.writer(datacsv, dialect=(&quot;excel&quot;)) mainfileH = open(inputfile, 'rb') for line in mainfileH.readlines(): # print &quot;Debug: &quot; + line.replace('\\n', '') csvwriter.writerow([a for a in line.decode().split('\\t')]) datacsv.close() mainfileH.close() if __name__ == &quot;__main__&quot;: txt_list = [ x for x in os.listdir('.') if os.path.isfile(x) and os.path.splitext(x)[1] == '.txt' ] for txt in txt_list: outputfile = txt.split('txt')[0] + 'csv' txt2csv(txt, outputfile) dcm2niix recon-all 命令无法对文件夹形式的 DICOM 图像直接进行处理，借用 dcm2niix 库以及 parallel 可以进行批量转换。dcm2niix 默认将转换结果放到原 DICOM 文件夹内，不方便后续处理，所以用设置 -o 参数指定输出文件夹。 # 安装 sudo apt-get install pigz dcm2niix # 使用 # 将多个 DICOM 文件夹放到同一目录下，并避免有其他非 DICOM 文件 ls | parallel dcm2niix -o 目标输出文件夹 {} PETSurfer PETSurfer 是 Freesurfer 6 中引入的新功能，包含部分容积校正以及力学建模等功能。 创建一个分割 # 替换 SUBJECT gtmseg --s SUBJECT 此步操作会使用生成一个高精度的分割结果 SUBJECT/mri/gtmseg.mgz ，使用到原来的 ageg.mgz 提供皮层下结构，使用 ?h.aparc.annot 提供皮层结构，还将估计一些额外的脑结构。 PET 配准到 MR # 替换 PET_IMAGE, template名字也可以修改 # PET_IMAGE 为PET路径/PET文件名 mri_coreg --s subject --mov PET_IMAGE --reg template.reg.lta 检查配准结果使用以下命令： tkregisterfv --mov PET_IMAGE --reg template.reg.lta --surfs 部分容积校正 # 其中 PET_IMAGE FWHM 均需要替换 # PET_IMAGE 为PET路径/PET文件名 # 如果不需要参考脑桥代谢值，可以再命令中补充 --no-rescale # FWHM 取决于设备，医大一院用的2.8 mri_gtmpvc --i PET_IMAGE --reg template.reg.lta --psf 2.8 --seg gtmseg.mgz --default-seg-merge --auto-mask PSF .01 --mgx .01 --o gtmpvc.output 官网对各参数的解释如下： &gt;--psf FWHM is the full-width/half-max of the the point-spread function (PSF) of the scanner as measured in image space (also known as the burring function). The blurring function depends on the scanner and reconstruction method; here it is modeled as an isotropic Gaussian filter of the given FWHM. Eg, an HR+ is typically about 6mm. This parameter has nothing to do with applying smoothing. Set this to 0 to turn off PVC. If you don't know what to set this to, ask your PET physicist. &gt;--seg gtmseg.mgz is the segmentation created with gtmseg &gt;--default-seg-merge will merge several segmentations, eg, all the ventricular CSF segments will be merged into one ROI &gt;--auto-mask FWHM .01 will create a mask to exclude voxels from the analysis (saves time). Output volumes will be reduced to a bounding box around this mask (saves space) &gt;--mgx .01 Run Muller-Gartner analysis. 01 is the GM threshold. Only necessary if you want to do a voxel-wise analysis. &gt;--o gtmpvc.output This is the output folder. 此步生成了一个文件 ./gtmpvc.output/gtm.stats ，里面存放了各个 ROI 的代谢信息，阅读参考如下内容： 9 17 Left-Hippocampus subcort_gm 473 174.083 1.406 0.1216 9 = ninth row 17 = index for ROI Left-Hippocampus = name of ROI subcort_gm = tissue class 473 = number of PET voxels in the ROI 174 = variance reduction factor for ROI (based on GLM/SGTM) 1.406 = PVC uptake of ROI relative to Pons 0.1216 = resdiual varaince across voxels in the ROI 引入PET后的批处理 简单的PET批处理方法需要从转DICOM开始进行操作。首先切换到在目标目录打开终端并设置为SUBJECTS_DIR ，并建立两个存放DICOM的文件夹，然后分别讲MR和PET图像存进去： export SUBJECTS_DIR=$(pwd) # 分别为PET图像和MR图像建立一个名为PET和MR的文件夹，分隔开 mkdir MR mkdir PET 下面开始转换格式，转换的nii使用人名命名，如果有空格或者重复人名需要手动修正。 # 切换到MR文件夹，输出文件直接放到 SUBJECTS_DIR cd MR ls | parallel dcm2niix -o $SUBJECTS_DIR -f %n -b n {} # 切换到PET文件夹 cd ../PET ls | parallel dcm2niix -o $(pwd) -f pet_%n -b n {} # 返回 SUBJECTS_DIR cd .. 然后对MR进行分割 #此时目录应该是SUBJECTS_DIR ls *.nii | parallel recon-all –s {.} –i {} –all 然后处理PET，各命令含义见上一节： ls *.nii | parallel --jobs 4 gtmseg --s {.} ls *.nii | parallel mri_coreg --s {.} --mov PET/pet_{} --reg {.}.reg.lta # 配准结果检查不使用批处理 # 如果不需要参考脑桥代谢值，可以再命令中补充 --no-rescale # FWHM 需要指定一个值 ls *.nii | parallel --jobs 4 mri_gtmpvc --i PET/pet_{} --reg {.}.reg.lta --psf FWHM --seg gtmseg.mgz --default-seg-merge --auto-mask PSF .01 --mgx .01 --o {.}_gtmpvc.output 提取recon-all的统计结果 mkdir asegStats ls *.nii | parallel asegstats2table --subjects {.} --common-segs --meas volume --stats=aseg.stats --table=./asegStats/{.}_segststs.txt # https://surfer.nmr.mgh.harvard.edu/fswiki/aparcstats2table # aparcstats2table 需要分别提取左右脑的结果 mkdir aparcStats ls *.nii | parallel aparcstats2table --subjects {.} --hemi lh --meas thickness --parc=aparc --tablefile=./aparcStats/{.}_aparc_lh.txt ls *.nii | parallel aparcstats2table --subjects {.} --hemi rh --meas thickness --parc=aparc --tablefile=./aparcStats/{.}_aparc_rh.txt 提取 gtmseg 及其统计结果 mkdir gtmseg ls *.nii | parallel cp ./{.}/mri/gtmseg.mgz ./gtmseg/{.}_gtmseg.mgz mkdir gtmVolume ls *.nii | parallel asegstats2table --subjects {.} --common-segs --meas volume --stats=gtmseg.stats --table=./gtmVolume/{.}_gtmVolume.txt 提取PET处理结果 gtm.stats.dat mkdir gtmStats ls *.nii | parallel cp ./{.}_gtmpvc.output/gtm.stats.dat ./gtmStats/{.}.gtm.stats.dat 海马子区域分割 进行此步骤的前提是正确安装了matlab runtime，然后只需要执行 recon-all 命令 如果是一个新的待分割数据，需要重新开始 recon-all 过程 # bert可以自定义 recon-all -all -s bert -hippocampal-subfields-T1 如果之前进行过 recon-all 分割，只需要执行 # bert为原来的subject名称 recon-all -s bert -hippocampal-subfields-T1 分割结果存放在文件夹 $SUBJECTS_DIR/bert/mri/中，可以使用freeview查看分割结果 cd ./bert/mri freeview -v nu.mgz -v lh.hippoSfLabels-T1.v10.mgz:colormap=lut -v rh.hippoSfLabels-T1.v10.mgz:colormap=lut 有关分割结果的介绍，fs文档原文如下 The output will consist of six files (three for each hemisphere) that can be found under the subject's mri directory (in this example, $SUBJECTS_DIR/bert/mri/): [lr]h.hippoSfLabels-T1.v10.mgz: they store the discrete segmentation volume (lh for the left hemisphere, rh for the right) at 0.333 mm resolution. [lr]h.hippoSfLabels-T1.v10.FSvoxelSpace.mgz: they store the discrete segmentation volume in the FreeSurfer voxel space (normally 1mm isotropic, unless higher resolution data was used in recon-all with the flag -cm). [lr]h.hippoSfVolumes-T1.v10.txt: these text files store the estimated volumes of the subfields and of the whole hippocampi. Note that [lr]h.hippoSfLabels-T1.v10.mgz covers only a patch around the hippocampus, at a higher resolution than the input image. The segmentation and the image are defined in the same physical coordinates, so you can visualize them simultaneously with (run from the subject's mri directory): On the other hand [lr]h.hippoSfLabels-T1.v10.FSvoxelSpace.mgz lives in the same voxel space as the other FreeSurfer volumes (e.g., orig.mgz, nu.mgz, aseg.mgz), so you can use it directly to produce masks for further analyses, but its resolution is lower than that of [lr]h.hippoSfLabels-T1.v10.mgz. ","link":"https://yangt.me/post/freesurfer-use/"},{"title":"在Ubuntu18.04LTS中安装FreeSurfer","content":"本文档主要参考了FreeSurfer官方教程以及CSDN上的一篇文章Ubuntu 18.04安装FreeSurfer软件。由于系统与软件的更新迭代，必须进行一些额外的操作才能够成功安装。 修改1：2020-02-19 ​ 根据相关教程增加了freesurfer 6.0的补丁包安装步骤 修改2：2020-03-02 ​ 在使用过程中发现freesurfer依赖python环境，需要安装，补充在额外操作-Python版本中 修改3：2020-03-14 ​ 修改了一些输入错误 修改4：2020-08-03 ​ 新增清华镜像以及dcm2niix等库 修改5：2020-11-02 新增Matlab Runtime配置 下载FreeSurfer 官网给出了下载链接以及系统需求 Ubuntu里使用命令下载： wget ftp://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.0/freesurfer-Linux-centos6_x86_64-stable-pub-v6.0.0.tar.gz 将下载数据移动到/usr/local文件夹下并解压： sudo mv freesurfer-Linux-centos6_x86_64-stable-pub-v6.0.0.tar.gz /usr/local cd /usr/local sudo tar xzvf freesurfer-Linux-centos6_x86_64-stable-pub-v6.0.0.tar.gz 获取license 获取license的链接为：FreeSurfer Download and Registration，注册后邮箱会收到license.txt文件，复制其中内容。 创建license文本然后粘贴license内容： sudo touch freesurfer/license.txt sudo su cd /usr/local/freesurfer gedit license.txt 配置环境变量 输入以下指令： sudo gedit /etc/profile 在打开文件的最后输入以下语句： export FREESURFER_HOME=/usr/local/freesurfer 输入以下指令： sudo gedit /etc/bash.bashrc 在打文件最后输入以下语句： export FREESURFER_HOME=/usr/local/freesurfer source $FREESURFER_HOME/SetUpFreeSurfer.sh 期间如果出现如下提示忽略即可： Set document metadata failed: 不支持设置属性 metadata::gedit-encoding 经过上述环境变量设置之后，每次启动终端都会有FreeSurfer的相关信息输出： -------- freesurfer-Linux-centos6_x86_64-stable-pub-v6.0.0-2beb96c -------- Setting up environment for FreeSurfer/FS-FAST (and FSL) FREESURFER_HOME /usr/local/freesurfer FSFAST_HOME /usr/local/freesurfer/fsfast FSF_OUTPUT_FORMAT nii.gz SUBJECTS_DIR /usr/local/freesurfer/subjects MNI_DIR /usr/local/freesurfer/mni 额外操作 缺少的库 由于我操作的Ubuntu系统之前从未使用过，在启动FreeSurfer时会出现报错，提示缺少库文件，比如： # 缺少tcsh bash: /usr/local/freesurfer/bin/recon-all: /bin/tcsh: 解释器错误: 没有那个文件或目录 # 缺少libpng12 freeview.bin: error while loading shared libraries: libpng12.so.0: cannot open shared object file: No such file or directory # 缺少libjpg freeview.bin: error while loading shared libraries: libjpeg.so.62: cannot open shared object file: No such file or directory 其中tcsh与libjpd可以直接安装，在Ubuntu 16.10+的系统中，libpng12已经被弃用，无法直接安装，需要手动下载编译，在进行操作前建议将 Ubuntu 镜像替换为 清华镜像 。 # 替换镜像之后 sudo apt update sudo apt upgrade sudo apt install tcsh libjpeg62 dcm2niix htop wget http://mirrors.kernel.org/ubuntu/pool/main/libp/libpng/libpng12-0_1.2.54-1ubuntu1_amd64.deb sudo dpkg -i libpng12-0_1.2.54-1ubuntu1_amd64.deb Python版本 在对recon-all命令得到的结果进行统计学分析是使用到了两个命令asegstats2table，aparcstats2table，这两个命令直接执行会报错：/usr/bin/env: &quot;python&quot;: 没有那个文件或目录，这是因为在我使用的Ubuntu18.04LTS中，默认的python为python3而且需要使用命令python3调出，解决这个问题可以将python命令绑定为python3，但是网络上查到的和freesurfer有关的内容均使用了python2，因此直接安装python2即可解决问题。 sudo apt-get install python Tips：在安装是如果提示： E: 无法获得锁 /var/lib/dpkg/lock-frontend - open (11: 资源暂时不可用) E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it? 参考一篇博客的内容，两种解决方法： # 杀掉apt-get进程： ps aux | grep apt-get sudo kill PID # 强制解锁： sudo rm /var/cache/apt/archives/lock sudo rm /var/lib/dpkg/lock # 经检验第二种方法有用，在使用第二种方法后如果仍然出现报错，但是查看进程发现并没有apt-get进程信息，此时通过重启系统，再重新安装软件，发现可以成功安装。 以上是我在安装过程中遇到的库缺失情况，实际操作中需要根据报错查看缺失库的详情 用例测试 测试FreeSurfer能否正常工作可以直接使用官方的例程： FreeSurfer comes with two sample data files (sample-001.mgz and sample-002.mgz) as well as a fully recon-ed subject named bert. These data files can be used to test that your FreeSurfer installation was done properly. To test your installation, please try the following examples: Example 1: Convert the sample-001.mgz to nifti format. $&gt; cp $FREESURFER_HOME/subjects/sample-001.mgz . $&gt; mri_convert sample-001.mgz sample-001.nii.gz ... reading from sample-001.mgz... TR=7.25, TE=3.22, TI=600.00, flip angle=7.00 i_ras = (-0, -1, -0) j_ras = (-0, 0, -1) k_ras = (-1, 0, 0) writing to sample-001.nii.gz... Example 2: Perform a full recon-all on the nifti file. $&gt; export SUBJECTS_DIR=&lt;path to subject directory&gt; $&gt; recon-all -i sample-001.nii.gz -s bert -all (creates a folder called bert in SUBJECTS_DIR) Example 3: Perform a full recon-all on a pre-existing subject folder $&gt; export SUBJECTS_DIR=&lt;path to subject directory&gt; $&gt; recon-all -s bert -all Example 4: View the output volumes, surfaces and subcortical segmentation of the fully recon-ed subject bert. $&gt; cd $SUBJECTS_DIR $&gt; freeview -v \\ bert/mri/T1.mgz \\ bert/mri/wm.mgz \\ bert/mri/brainmask.mgz \\ bert/mri/aseg.mgz:colormap=lut:opacity=0.2 \\ -f \\ bert/surf/lh.white:edgecolor=blue \\ bert/surf/lh.pial:edgecolor=red \\ bert/surf/rh.white:edgecolor=blue \\ bert/surf/rh.pial:edgecolor=red # 正常的话应该出现加载完成示例图像的GUI 补丁包 由于6.0.0版本部分指令运行时存在bug，因此先打好补丁避免遇到类似问题。下载freesurfer 6.0.0 patch：6.0.0 patch地址 如果需要其他版本补丁的下载，也可以在这个网站去查询对应版本是否发布patch包：freesurfer 根据readme文件的说明，分别备份freesurfer下这些指令的文件，然后将补丁文件复制过去覆盖即可，Terminal下输入： wget ftp://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.0-patch/make_average_subject wget ftp://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.0-patch/make_average_surface wget ftp://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.0-patch/mri_aparc2aseg.linux wget ftp://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.0-patch/mri_glmfit-sim wget ftp://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.0-patch/mri_segstats.linux wget ftp://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.0-patch/mris_anatomical_stats.linux wget ftp://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.0-patch/recon-all wget ftp://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/6.0.0-patch/vol2subfield sudo cp $FREESURFER_HOME/bin/make_average_subject $FREESURFER_HOME/bin/make_average_subject.backup sudo cp make_average_subject $FREESURFER_HOME/bin/make_average_subject sudo cp $FREESURFER_HOME/bin/make_average_surface $FREESURFER_HOME/bin/make_average_surface.backup sudo cp make_average_surface $FREESURFER_HOME/bin/make_average_surface sudo cp $FREESURFER_HOME/bin/mri_aparc2aseg $FREESURFER_HOME/bin/mri_aparc2aseg.backup sudo cp mri_aparc2aseg.linux $FREESURFER_HOME/bin/mri_aparc2aseg sudo cp $FREESURFER_HOME/bin/mri_glmfit-sim $FREESURFER_HOME/bin/mri_glmfit-sim.backup sudo cp mri_glmfit-sim $FREESURFER_HOME/bin/mri_glmfit-sim sudo cp $FREESURFER_HOME/bin/mri_segstats $FREESURFER_HOME/bin/mri_segstats.backup sudo cp mri_segstats.linux $FREESURFER_HOME/bin/mri_segstats sudo cp $FREESURFER_HOME/bin/mris_anatomical_stats $FREESURFER_HOME/bin/mris_anatomical_stats.backup sudo cp mris_anatomical_stats.linux $FREESURFER_HOME/bin/mris_anatomical_stats sudo cp $FREESURFER_HOME/bin/recon-all $FREESURFER_HOME/bin/recon-all.backup sudo cp recon-all $FREESURFER_HOME/bin/recon-all # 原freesurfer中好像没有vol2subfield，无需备份直接拷贝即可 sudo cp vol2subfield $FREESURFER_HOME/bin/vol2subfield Matlab Runtime Freesurfer关于Matlab Runtime的文档 使用 fs_install_mcr 自动安装需要的Matlab，步骤如下 # 首次需要安装fs_install_mcr cd $FREESURFER_HOME/bin sudo curl https://raw.githubusercontent.com/freesurfer/freesurfer/dev/scripts/fs_install_mcr -o fs_install_mcr &amp;&amp; chmod +x fs_install_mcr # FS 6.0版本下载 Matlab r2012b fs_install_mcr R2012b 但是我在执行过程中遇到上面的命令无法下载Matlab安装包就报错了，另一个方案就是手动去 matlab官网 下载 r2012b linux版，下面可以执行命令进行下载。 # 新建一个文件夹进行操作 mkdir matlab cd matlab wget https://ssd.mathworks.com/supportfiles/MCR_Runtime/R2012b/MCR_R2012b_glnxa64_installer.zip unzip MCR_R2012b_glnxa64_installer.zip sudo ./install -mode silent -agreeToLicense yes 然后需要将matlab的安装目录通过软链接映射到Freesurfer的目录下，matlab安装目录默认为 /usr/local/MATLAB/MATLAB_Compiler_Runtime cd $FREESURFER_HOME ln -s /usr/local/MATLAB/MATLAB_Compiler_Runtime/v80 MCRv80 ","link":"https://yangt.me/post/install-freesurfer-on-ubuntu1804lts/"},{"title":"WIFI断连自动连接脚本","content":"疫情期间需要远程访问电脑进行工作，实验室电脑一旦出现网络问题就只能求助老师到现场重连WIFI。为了监测网络状态，并在断网时能够及时自动重新连回实验室路由器，编写了以下脚本。 获取目标WIFI的ssid 首先使用如下命令查看周围的WIFI netsh wlan show networks mode=bssid 然后查看已经连接过WIFI的配置文件 netsh wlan show profiles 记下目标WIFI的名称与ssid，应该是相同的，不能记错，否则断开后程序再也无法连接。 实际上，连接WIFI的主要命令只有两句 # XXX按目标WIFI填写 netsh wlan disconnect netsh wlan connect ssid=XXX name=XXX Windows批处理脚本 此脚本的内容为每十分钟检测电脑与百度和大连理工大学网信中心之间的连接性，在确认断连后执行上面的重连命令。202.118.66.6为大连理工大学网信中心DNS服务器IP，非大连理工大学校园网环境无法使用 @echo off echo WIFI自动重连服务正在进行中....... echo 停止服务请按 Ctrl+C :begin echo %date% %time% ping baidu.com rem echo %errorlevel% if %errorlevel%==1 goto ping2 goto loop :ping2 ping 202.118.66.6 rem echo %errorlevel% if %errorlevel%==1 goto reconnect goto loop :reconnect echo %date% %time% 网络主动断开 netsh wlan disconnect echo %date% %time% 正在重新连接中.... netsh wlan connect ssid=MICCAI_5G name=MICCAI_5G echo %date% %time% 已发送连接请求....ssid=MICCAI_5G goto loop :loop timeout 600 goto begin 总结 脚本已经部署运行，还未有机会触发重连功能。 除了监测与互联网的连接性外，还可以采取每日定时断开WIFI重新连接的方法，或者在Windows系统的计划任务程序功能中设置WIFI状态触发等方式。 ","link":"https://yangt.me/post/reconnect-wifi/"},{"title":"在vps上搭建Jupyter环境","content":"之前在吴恩达的深度学习课上接触了Jupyter，一直在本地使用，每次想启动都得打开PowerShell输入jupyter notebook的命令，启动后的目录下还包含路径下其他文件，很是不够方便。 其实我一直有一个vps服务器默默工作在大洋彼岸，心想着可以在上面搭建个Jupyter环境，趁清明假期配置了一下。 Jupyter简介 （来自维基百科）Jupyter Notebook（前身是IPython Notebook）是一个基于Web的交互式计算环境，用于创建Jupyter Notebook文档。Notebook一词可以通俗地引用许多不同的实体，主要是Jupyter Web应用程序、Jupyter Python Web服务器或Jupyter文档格式（取决于上下文）。Jupyter Notebook文档是一个JSON文档，遵循版本化模式，包含一个有序的输入/输出单元格列表，这些单元格可以包含代码、文本（使用Markdown语言）、数学、图表和富媒体，通常以“.ipynb”结尾扩展。 搭建流程 演示系统为Debian 9 ×64，为了教程新建的实例，一切从零开始。为了方便，用户直接用了root，如果服务器里面有重要数据的话建议新建一个用户。 使用ssh软件登录一下服务器。首先下载一下Anaconda，里面集成了很多常用的Python包，其中就有今天要用的Jupyter。Anaconda官网链接为：https://www.anaconda.com 然后使用wget命令把安装包下载下来。 wget https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh 之后使用 bash Anaconda3-2019.03-Linux-x86_64.sh 命令一路安装，选择默认安装路径或者自定义，等待安装完成。然后重启终端。输入conda --version 会得到conda版本号，代表安装成功。 接下来输入Python进入Python环境，分别执行from notebook.auth import passwd与passwd()设置notebook密码。把生成的sha1那一串保存下来备用。退出Python环境。 执行jupyter notebook --generate-config命令生成jupyter配置文件。vim ~/.jupyter/jupyter_notebook_config.py进入编辑。插入图中4行命令，最后一行的sha1为刚刚保存的sha1。保存并退出。 然后就可以测试是否配置成功了。执行jupyter notebook --allow-root 。--allow-root是root用户才需要输入的部分。 浏览器中输入你的IP:端口，能打开jupyter界面表示安装成功。密码是刚才自己设置的密码。 如果想自定义默认目录的话需要再打开jupyter配置文件，加入一行c.NotebookApp.notebook_dir = '自定义目录'，不再演示了。 接下来新建一个Python3文件，Hello World &amp; Hello CoolApk 最后回到终端，停掉现在的jupyter进程。为了将jupyter作为后台服务进行，同时不会收到当前终端的影响，将启动命令改为 nohup jupyter notebook --allow-root &amp; 总结 远程敲代码成就达成√ 手机敲代码成就达成√ ","link":"https://yangt.me/post/jupyter-env/"},{"title":"Windows系统下TensorFlow-GPU环境搭建","content":"以 Windows 7 SP1 专业版系统为例，进行 Windows 下 TensorFlow GPU 环境的配置，尽可能复现课题组 Ubuntu 服务器中的版本。 1. Anaconda3 首先使用 Anaconda3 建立一个 Python 版本为 3.6 的新环境。 # Anaconda3 下载链接 清华镜像: https://mirror.tuna.tsinghua.edu.cn/help/anaconda/ 官网链接: https://www.anaconda.com/distribution/#download-section # 新建 conda 环境 conda create -n ENV_NAME python=3.6 下面所有涉及 Python 的内容都会在该环境中进行，如果不在该环境中，切换至该环境的命令为 conda activate ENV_NAME 清华的链接里提供了替换镜像的方法，以便提高下载速度 2. Visual Studio 安装 CUDA 的前提时安装有 Visual Studio，CUDA 9.0 支持 vs2010 - vs2019，我选择了 Visual Studio 2013 版，下载之后全部默认安装即可。 # Visual Studio 2013 下载链接 中文旗舰版：http://download.microsoft.com/download/0/7/5/0755898A-ED1B-4E11-BC04-6B9B7D82B1E4/VS2013_RTM_ULT_CHS.iso 其他版本参考：https://blog.csdn.net/skykingf/article/details/12883655 3. Nvidia 驱动 Nvidia 驱动包括 3 个，显卡驱动（版本无要求）、CUDA 9.0、以及 cuDNN 7.0.5。需要按照上述次序安装。要和服务器中的 CUDA 9.0 以及 cuDNN 7.1.2 对应，上述 Windows 版本为唯一选择，否则会报错 # 显卡驱动 Nvidia 官网：https://www.nvidia.com/Download/index.aspx?lang=cn # CUDA 9.0 选择对应的系统：https://developer.nvidia.com/cuda-90-download-archive # cuDNN 7.0.5 可能需要先注册，选择：Download cuDNN v7.0.5 (Dec 5, 2017), for CUDA 9.0 https://developer.nvidia.com/rdp/cudnn-archive 下载的显卡驱动与 CUDA 是安装的，直接默认安装，cuDNN 是一个压缩包，解压后将其中的 bin, include, lib 文件夹覆盖到 CUDA 的安装目录，默认安装即是 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0 CUDA 验证 安装完成后打开 CUDA 的例程文件夹，默认为 C:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v9.0 选择对应 vs 版本的例程打开，在 vs 中右键 build 一下，无报错即可。（vs 要用管理员身份运行） 4. TensorFlow 等 # 安装 tensorflow-gpu 1.7 # 优先使用 conda 安装，因为 conda 会考虑到依赖库之间的版本兼容性 conda install tensorflow-gpu=1.7 # 我安装的 conda 不知为何联网，只能换用 pip pip install tensorflow-gpu==1.7 安装完之后进入 Python 环境，测试 TensorFlow，import tensorflow as tf 有可能会出现下面的警告，这是 Numpy 版本不兼容的问题 ...\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint8 = np.dtype([(&quot;qint8&quot;, np.int8, 1)]) 解决这个问题需先查看 Numpy 的版本，然后决定是否替换。 # 查看 Numpy 版本 pip show numpy # 更改为 1.14.5 （与服务器相同） pip install numpy==1.14.5 然后再进入 Python 环境，执行下面语句，能正常输出 GPU 信息并且无报错即可。 import tensorflow as tf sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) ","link":"https://yangt.me/post/tensorflow-gpu-env-under-windows/"},{"title":"服务器被SSH暴力破解解决方案","content":"服务器端使用Debian 9×64系统，发现大量不存在的用户名登陆失败记录，于是使用Fail2ban进行IP封禁。 查看系统登录日志（仅root用户） last|less会返回一系列登录成功的记录，格式为 用户名+终端位置+IP地址+登录时间+在线时长 root pts/1 IP Sat May 25 17:23 still logged in lastb会返回一系列登录失败的记录，格式为 steam1 ssh:notty 188.165.44.214 Sat May 25 06:19 - 06:19 (00:00) dan ssh:notty 134.175.18.237 Sat May 25 06:19 - 06:19 (00:00) steam1 ssh:notty 188.165.44.214 Sat May 25 06:19 - 06:19 (00:00) 12345678 ssh:notty 82.223.130.223 Sat May 25 06:18 - 06:18 (00:00) 12345678 ssh:notty 82.223.130.223 Sat May 25 06:18 - 06:18 (00:00) tom1 ssh:notty 164.132.62.233 Sat May 25 06:18 - 06:18 (00:00) # 查看不存在的用户名登录失败的日志 grep &quot;Failed password for invalid user&quot; /var/log/auth.log | awk '{print $13}' | sort | uniq -c | sort -nr | more # 查看root账户登录失败记录 sudo grep &quot;Failed password for root&quot; /var/log/auth.log | awk '{print $11}' | sort | uniq -c | sort -nr | more 下面的登录失败记录只是冰山一角 199 92.50.249.166 199 47.107.55.172 199 195.114.210.238 199 194.56.72.6 199 159.89.149.46 更改SSH端口 可以从输出结果看到这个服务器被攻击的相当频繁，还好之前改过SSH端口。 # 一键更改端口 wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssh_port.sh &amp;&amp; chmod +x ssh_port.sh &amp;&amp; bash ssh_port.sh 下面是手动方法： vim /etc/ssh/sshd_config打开SSH的配置文件，可以找到#Port字样，默认一般为22，非常不安全，将其注释去掉并在其后添加一行，即Port ***，添加新的SSH端口，在验证新端口好用后再将22端口注释掉。 在修改端口之后需要重启SSH服务 /etc/init.d/sshd restart //或者 service sshd restart 如果还是访问不通，需要进行防火墙配置 /etc/init.d/iptables stop //或者 service iptables stop 或者在防火墙过滤规则中上增加一条，允许对新增的端口的访问： vim /etc/sysconfig/iptables :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT *********** -A INPUT -m state --state NEW -m tcp -p tcp --dport 2022 -j ACCEPT *********** -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT Fail2ban配置 之前尝试使用过DenyHosts，其已经很长时间没有进行维护而且它用的Python2与服务器上部署的Python3有不兼容的现象，弃用。 Fail2ban是一款实用软件，可以监视你的系统日志，然后匹配日志的错误信息（正则式匹配）执行相应的屏蔽动作。一般需求的操作并不复杂，修改配置文件即可。 安装 apt-get install fail2ban 打开配置文件 vim /etc/fail2ban/jail.conf 配置文件翻译如下： 我并没有在服务器上配置邮件服务，也不需要邮件提醒，主要是修改前12行 [DEFAULT] # 忽略的IP列表,不受设置限制 ignoreip = 127.0.0.1/8 # 被封IP禁止访问的时间，单位是秒 bantime = 60000 # 检测时间，在此时间内超过规定的次数会激活fail2ban，单位是秒 findtime = 300 # 允许错误登录的最大次数 maxretry = 2 需要将Fail2ban设置为开机自启动 # 设置fail2ban开机启动 systemctl enable fail2ban systemctl start fail2ban # 启动与重启fail2ban service fail2ban start service fail2ban restart 日志查看功能 # 查看最近100条记录 ps.可以配合grep筛选已Ban列表 tail -100 /var/log/fail2ban.log 查看SSH服务监护状态，能看到当前被禁IP fail2ban-client status sshd ","link":"https://yangt.me/post/protect-server-under-ssh-cracking/"},{"title":"装机用所有软件合集","content":"下面的文章列出了电脑中必备的一些软件，标注了其官网或者可靠的下载方式 下载方式主要分为三种（按喜好程度排序）： Scoop/Chocolatey下载 微软应用商店UWP下载 传统官网x64/x86下载 和谐版下载 Scoop与Chocolatey Scoop与Chocolatey是我最近发现的用于Windows的包管理工具，相当于Ubuntu中的apt-get；Chocolatey是更早的包管理工具，商业软件。两者的区别是前者将软件安装在用户文件夹下，后者将软件安装在Program Files文件夹中。Chocolatey安装软件不会生成快捷方式（均可更改，复杂） **目前遵循Scoop优于Chocolatey安装的原则，特殊软件除外 ** 打开 PowerShell 在 PowerShell 中输入下面内容，保证允许本地脚本的执行： set-executionpolicy remotesigned -scope currentuser 然后执行下面的命令安装 Scoop： iex (new-object net.webclient).downloadstring('https://get.scoop.sh') 静待脚本执行完成就可以了，安装成功后，让我们尝试一下： scoop help 搜索软件使用：scoop search * 安装软件使用：scoop install * 同理安装Chocolatey Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://Chocolatey.org/install.ps1')) 一键安装命令 原则：Scoop中有就不使用Chocolatey 首先开启全局翻墙，然后使用Scoop安装7zip, git与sudo scoop install 7zip git sudo 然后安装extra仓库 scoop bucket add extras scoop bucket add Ash258 'https://github.com/Ash258/scoop-Ash258.git' 最后执行一键命令 # 已经经过测试可用的各个软件，有些软件可用scoop，但不适合 scoop install 7zip anydesk aria2 aria-ng-gui captura dismplusplus freedownloadmanager geekuninstaller git goldendict innounp mobaxterm pandownload putty pycharm rufus screentogif sudo teamviewer trafficmonitor typora vncviewer vscode xmind8 sudo choco install --yes raidrive fluent-terminal sandboxie logitechoptions vmwareworkstation qtranslate 最后执行一键命令 # 已经经过测试可用的各个软件，有些软件可用scoop，但不适合 scoop install 7zip anydesk aria2 aria-ng-gui captura dismplusplus freedownloadmanager geekuninstaller git goldendict innounp mobaxterm pandownload putty pycharm rufus screentogif sudo teamviewer trafficmonitor typora vncviewer vscode xmind8 sudo choco install --yes raidrive fluent-terminal sandboxie logitechoptions vmwareworkstation qtranslate 常用软件 网上冲浪 Google Chrome 最好用的浏览器，没有之一，配合谷歌账户使用效果更佳，所用插件直接登陆账号后恢复 Scoop/Chocolatey (googlechrome) x64 V2ray Internet访问工具，墙不平何以平天下 Scoop (v2rayn) x64 解压缩 Bandizip 解压缩软件，界面美观无广告（7.x 版本之前免费，官网有 老版本 链接） Scoop/Chocolatey (bandizip) x64 7z 开源的解压缩软件，功能很强但是丑，可以进行简单的美化，详见少数派这篇文章：如何让简陋的 7-Zip 的界面现代化 。 即时通讯 Tim / 微信 桌面端TIM简洁好用，没有QQ的“丰富”的内容与广告，适合专注通信与协作。UWP版微信已经停更，还是使用官网下载的版本吧。 微软应用商店UWP安装 x64 Telegram 被墙的即时通讯软件，安卓端与桌面端的开发都很规范，干翻 QQ 微信之流。 办公写作 Typora Markdown写作软件，本文由Typora完成，配合Pandoc可进行不同格式的导出 Scoop/Chocolatey (typora) （测试发现装不上） x64 Gridea Gridea 是一个静态博客写作客户端，帮助你更容易地构建并管理博客或任何静态站点。目前我的 博客 就是使用 Gridea 搭建在 GitHub Pages 上 Sumatra PDF 极简PDF阅读器，有效阅读面积大，没有批注等功能 Scoop/Chocolatey (sumatrapdf) x64 Microsoft 365 Office 订阅制产品，原名 Office 365，功能强大，可使用 Office Tool Plus 进行自定义组件安装，日常仅需 Word，Excel，PowerPoint 三个组件 x64 和谐版 Microsoft To Do Todo软件，可与安卓端联动 微软应用商店 Yomail 邮件应用，已经凉了，但是还能用 网易邮箱大师 目前在用，界面好看，还算稳定 GoldenDict / QTranslate 开源的词典软件，可屏幕取词，后者更加轻量，但不支持字典 Scoop/Chocolatey (goldendict) Chocolatey (qtranslate) x64 图像视频 Potplayer 功能强大，皮肤自定义，在用Zune皮肤 Scoop/Chocolatey (potplayer) x64 ScreenToGif 体积极小的录屏转Gif的软件，有安装版和绿色版，开源 Scoop/Chocolatey (screentogif) x64 Captura 专业的录屏软件，可调整帧率与质量 Scoop/Chocolatey (captura) x64 Honeyview 专业的看图软件，可为PSD文件生成缩略图，查看psd图像 Scoop/Chocolatey (honeyview) x64 Adobe全家桶 Photoshop，Premier Pro，Acrobat DC等 和谐版 效率工具 Listary 文件搜索神器，也许逐渐会被windows搜索替代，目前的开发版开始适配高分屏 Scoop/Chocolatey (listary) x64 Listary Pro有和谐版 Snipaste 方便快捷的截图贴图软件，可自定义截图快捷键，开源 微软应用商店UWP安装，实际上是转制版本 Scoop x64 TrafficMonitor 网速监控悬浮窗软件，内嵌到任务栏，开源 Scoop (trafficmonitor) x64 Calibre Kindle配套的电子书管理软件，泡面警告 Scoop/Chocolatey (calibre) x64 文件同步 坚果云 科研笔记以及文档备份等用途 x64 OneDrive Windows 系统自带，开通 Microsoft 365 之后空间扩展至 1T，与 Office 系列软件完美联动。不开会员也可以通过万能的某宝将空间扩展至 15G 远程访问 TeamViewer 远程访问工具，TeamViewer老牌，被国内垃圾代理商代理，现已难用至极 Scoop/Chocolatey (teamviewer anydesk) x64 AnyDesk 开源的远程访问软件，使用体验不佳 向日葵 国产远程软件，免费用户有 1M 带宽，可以用 ToDesk 国产远程软件，疫情期间的优秀产品，目前体验很棒，全平台支持 系统工具 Notepad2-mod 使用一个脚本可替代系统记事本，支持代码高亮 Scoop/Chocolatey (notepad2-mod) x64 替换系统记事本.bat @ECHO OFF PUSHD %~DP0 taskkill /f /im notepad*>NUL 2>NUL Md \"%WinDir%\\System32\\test_permissions\" 2>NUL||(Echo 请使用右键管理员身份运行&&Pause >NUL&&Exit) Rd \"%WinDir%\\System32\\test_permissions\" 2>NUL SetLocal EnableDelayedExpansion if not exist \"%WinDir%\\SysWOW64\" reg add \"HKLM\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options\\notepad.exe\" /v \"Debugger\" /t REG_SZ /d \"\\\"%~dp0Notepad2.exe\\\" /z\" /f if exist \"%WinDir%\\SysWOW64\" reg add \"HKLM\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options\\notepad.exe\" /v \"Debugger\" /t REG_SZ /d \"\\\"%~dp0Notepad2_x64.exe\\\" /z\" /f exit 恢复系统记事本.bat @ECHO OFF PUSHD %~DP0 taskkill /f /im notepad*>NUL 2>NUL Md \"%WinDir%\\System32\\test_permissions\" 2>NUL||(Echo 请使用右键管理员身份运行&&Pause >NUL&&Exit) Rd \"%WinDir%\\System32\\test_permissions\" 2>NUL SetLocal EnableDelayedExpansion reg delete \"HKLM\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options\\notepad.exe\" /f reg delete \"HKLM\\Software\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options\\notepad.exe\" /f exit RaiDrive 将网盘映射到资源管理器的软件，开源 Chocolatey (raidrive) x64 Fluent Terminal 好看的第三方命令行，颜值即正义，再用主题为 Dracula Chocolatey (fluent-terminal) x64 Sandboxie 沙盒 沙盒软件，用于安装百度云那种软件 Chocolatey (sandboxie) x64 Rufus / UltraISO 系统盘 启动盘制作工具，Rufus 更加先进，UltraISO 为收费软件，但是可以无限试用 Scoop （rufus） x64 智能任务栏 比windows自带好用的任务栏隐藏策略 微软应用商店 HashTab 哈希值查看软件，集成在‘属性’中 x64 GeekUninstall 卸载 卸载软件，可附带删除残留文件与注册表 Scoop/Chocolatey (geekuninstall) x64 VMware 虚拟机 虚拟机，直接使用密钥可和谐 Chocolatey (vmwareworkstation) x64 Qttabbar 将资源管理器标签化的工具，资源管理器该有的样子 PasteEx 将剪切板内容粘贴为txt的工具，集成到右键菜单 Logitech Options 罗技键鼠设置软件，可自定义快捷键功能 Chocolatey (logitechoptions) x64 下载 Free Download Manager 开源的下载工具，可下载种子与磁力链接，毕竟 IDM 收费而且颜值即正义 Scoop/Chocolatey (freedownloadmanager) x64 AriaNG-GUI 拥有 GUI 的 aira2 下载工具，实测速度优于其他软件 Scoop (aria-ng-gui) x64 影音娱乐 Bilibili 233333 微软应用商店 网易云音乐 随缘听歌，UWP好久没更新了 微软应用商店 x64 我爱科研 Pycharm Python IDE，社区版免费，启动慢是用为联网验证 Scoop/Chocolatey (pycharm/pycharm-community) x64 Visual Studio Code(VS Code) Visual Studio Code是由巨硬开发的，开源的全平台代码编辑器。Scoop安装的VSCode自带了右键的注册表文件，需要手动执行。 Scoop/Chocolatey (vscode) x64 MATLAB 工程用，功能强大，装一下十几个G就没了 x64 MITK / AnatomySketch 医学图像相关软件 x64 MathType 公式编辑器 公式编辑器，没法用了，可以改用 $ \\LaTeX$ ，有一个好用的在线编辑器 LaTeX公式编辑器 和谐版 MobaXterm/Putty SHH工具，用于访问服务器 Scoop/Chocolatey (mobaxterm putty) x64 VncViwer 用于图形化操作课题组服务器 Scoop/Chocolatey (vncviwer/vnc-viwer) x64 Zotero 文献管理工具，开源，使用坚果云同步 Scoop/Chocolatey (zotero) x64 其他 其他需要下载使用的非软件型辅助工具 Scoop下载来的git配置 右键菜单里添加 git bash here 新建注册表文件 git bash here.reg, 内容如下（路径按需修改） Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\directory\\background\\shell\\Git Bash Here] &quot;icon&quot;=&quot;C:\\\\Users\\\\用户名\\\\scoop\\\\apps\\\\git\\\\current\\\\mingw64\\\\share\\\\git\\\\git-for-windows.ico&quot; [HKEY_CLASSES_ROOT\\directory\\background\\shell\\Git Bash Here\\command] @=&quot;C:\\\\Users\\\\用户名\\\\scoop\\\\apps\\\\git\\\\current\\\\git-bash.exe&quot; 更纱黑体 基于思源黑体的开源中文字体，有等距模式，适合终端，腾讯镜像Sarasa-Gothic noMeiryoUI 替换系统字体显示的小工具，拯救768P屏幕 Zune皮肤 Potplayer皮肤，简洁美观 Tcping 测试海外服务器是否被TCP阻断的工具 下载好tcping工具后，将可执行程序（tcping.exe或者tcping64.exe）拷贝至C:\\Windows\\System32目录下，这个目录是所有工具的默认路径，放在这里就不需要指定工具所在路径了。 ","link":"https://yangt.me/post/apps-recommended/"}]}